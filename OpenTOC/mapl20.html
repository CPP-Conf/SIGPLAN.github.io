<html xmlns:bkstg="http://www.atypon.com/backstage-ns" xmlns:urlutil="java:com.atypon.literatum.customization.UrlUtil" xmlns:pxje="java:com.atypon.frontend.services.impl.PassportXslJavaExtentions">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <meta http-equiv="Content-Style-Type" content="text/css"><style type="text/css">
            #DLtoc {
            font: normal 12px/1.5em Arial, Helvetica, sans-serif;
            }

            #DLheader {
            }
            #DLheader h1 {
            font-size:16px;
            }

            #DLcontent {
            font-size:12px;
            }
            #DLcontent h2 {
            font-size:14px;
            margin-bottom:5px;
            }
            #DLcontent h3 {
            font-size:12px;
            padding-left:20px;
            margin-bottom:0px;
            }

            #DLcontent ul{
            margin-top:0px;
            margin-bottom:0px;
            }

            .DLauthors li{
            display: inline;
            list-style-type: none;
            padding-right: 5px;
            }

            .DLauthors li:after{
            content:",";
            }
            .DLauthors li.nameList.Last:after{
            content:"";
            }

            .DLabstract {
            padding-left:40px;
            padding-right:20px;
            display:block;
            }

            .DLformats li{
            display: inline;
            list-style-type: none;
            padding-right: 5px;
            }

            .DLformats li:after{
            content:",";
            }
            .DLformats li.formatList.Last:after{
            content:"";
            }

            .DLlogo {
            vertical-align:middle;
            padding-right:5px;
            border:none;
            }

            .DLcitLink {
            margin-left:20px;
            }

            .DLtitleLink {
            margin-left:20px;
            }

            .DLotherLink {
            margin-left:0px;
            }

        </style><title>MAPL 2020: Proceedings of the 4th ACM SIGPLAN International Workshop on Machine Learning and
         Programming Languages
      </title>
   </head>
   <body>
      <div id="DLtoc">
         <div id="DLheader">
            <h1>MAPL 2020: Proceedings of the 4th ACM SIGPLAN International Workshop on Machine Learning and
               Programming Languages
            </h1><a class="DLcitLink" title="Go to the ACM Digital Library for additional information about this proceeding" href="https://dl.acm.org/doi/proceedings/10.1145/3394450"><img class="DLlogo" alt="Digital Library logo" height="30" src="https://dl.acm.org/specs/products/acm/releasedAssets/images/footer-logo1.png">
               Full Citation in the ACM Digital Library
               </a></div>
         <div id="DLcontent">
            <h2>SESSION: Papers</h2>
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" href="https://dl.acm.org/doi/abs/10.1145/3394450.3397466">Generating correctness proofs with neural networks</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Alex Sanchez-Stern</li>
               <li class="nameList">Yousef Alhessi</li>
               <li class="nameList">Lawrence Saul</li>
               <li class="nameList Last">Sorin Lerner</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Foundational verification allows programmers to build software which has been empirically
                     shown to have high levels of assurance in a variety of important domains. However,
                     the cost of producing foundationally verified software remains prohibitively high
                     for most projects, as it requires significant manual effort by highly trained experts.
                     In this paper we present Proverbot9001, a proof search system using machine learning
                     techniques to produce proofs of software correctness in interactive theorem provers.
                     We demonstrate Proverbot9001 on the proof obligations from a large practical proof
                     project, the CompCert verified C compiler, and show that it can effectively automate
                     what were previously manual proofs, automatically producing proofs for 28% of theorem
                     statements in our test dataset, when combined with solver-based tooling. Without any
                     additional solvers, we exhibit a proof completion rate that is a 4X improvement over
                     prior state-of-the-art machine learning models for generating proofs in Coq.
                  </p>
                  	
               </div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" href="https://dl.acm.org/doi/abs/10.1145/3394450.3397465">Semi-static type, shape, and symbolic shape inference for dynamic computation graphs</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Momoko Hattori</li>
               <li class="nameList">Shimpei Sawada</li>
               <li class="nameList">Shinichiro Hamaji</li>
               <li class="nameList">Masahiro Sakai</li>
               <li class="nameList Last">Shunsuke Shimizu</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>The growing interest in deep learning has created a demand to compile computation
                     graphs to accelerate execution and to deploy applications on various devices. Modern
                     deep learning frameworks construct computation graphs dynamically. This gives rise
                     to the problem of inferring types of dynamic computation graphs. Two approaches are
                     known. One of them is a dynamic approach that constructs the computation graph from
                     the execution trace of an actual input. While this approach is straightforward, the
                     results of the shape inference will consist of only concrete values and is often difficult
                     for users to interpret. The other one performs static analysis over the source program.
                     This method can produce symbolic shape inference results but suffers from the dynamic
                     nature of the host programming language Python. 
                  </p> 
                  <p> In this paper, we propose a novel approach for type, shape, and symbolic shape inference
                     of dynamic computation graphs as a mixture of the above two methods. We present results
                     of applying our prototype inference engine for networks written with PyTorch and demonstrate
                     its effectiveness for nontrivial networks.
                  </p>
                  	
               </div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" href="https://dl.acm.org/doi/abs/10.1145/3394450.3397468">On the challenges in programming mixed-precision deep neural networks</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Ruizhe Zhao</li>
               <li class="nameList">Wayne Luk</li>
               <li class="nameList">Chao Xiong</li>
               <li class="nameList">Xinyu Niu</li>
               <li class="nameList Last">Kuen Hung Tsoi</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Deep Neural Networks (DNNs) are resilient to reduced data precision, which motivates
                     exploiting low-precision data formats for more efficient computation, especially on
                     custom hardware accelerators. Multiple low-precision types can be mixed to fit the
                     dynamic range of different DNN layers. However, these formats are not often supported
                     on popular microprocessors and Deep Learning (DL) frameworks, hence we have to manually
                     implement and optimize such novel data types and integrate them with multiple DL framework
                     components, which is tedious and error-prone. This paper first reviews three major
                     challenges in programming mixed-precision DNNs, including generating high-performance
                     arithmetic and typecast functions, reducing the recompilation time and bloated binary
                     size caused by excessive template specialization, and optimizing mixed-precision DNN
                     computational graphs. We present our approach, Lowgen, a framework that addresses
                     these challenges. For each challenge, we present our solution implemented and tested
                     on our in-house, TensorFlow-like DL framework. Empirical evaluation shows that Lowgen
                     can automatically generate efficient data type implementations that enable significant
                     speed-up, which greatly lowers the development effort and enhances research productivity
                     on mixed-precision DNN.
                  </p>
                  	
               </div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" href="https://dl.acm.org/doi/abs/10.1145/3394450.3397467">Learning quantitative representation synthesis</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Mayur Patil</li>
               <li class="nameList">Farzin Houshmand</li>
               <li class="nameList Last">Mohsen Lesani</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Software systems often use specialized combinations of data structures to store and
                     retrieve data. Designing and maintaining custom data structures particularly concurrent
                     ones is time-consuming and error-prone.We let the user declare the required data as
                     a high-level specification of a relation and method interface, and automatically synthesize
                     correct and efficient concurrent data representations. We present provably sound syntactic
                     derivations to synthesize structures that efficiently support the interface.We then
                     synthesize synchronization to support concurrent execution on the structures. Multiple
                     candidate representations may satisfy the same specification and we aim at quantitative
                     selection of the most efficient candidate. Previous works have either used dynamic
                     auto-tuners to execute and measure the performance of the candidates or used static
                     cost functions to estimate their performance. However, repeating the execution for
                     many candidates is time-consuming and a single performance model cannot be an effective
                     predictor of all workloads across all platforms. We present a novel approach to quantitative
                     synthesis that learns the performance model. We developed a synthesis tool called
                     Leqsy that trains an artificial neural network to statically predict the performance
                     of candidate representations. Experimental evaluations demonstrate that Leqsy can
                     synthesize near-optimum representations.
                  </p>
                  	
               </div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" href="https://dl.acm.org/doi/abs/10.1145/3394450.3397469">Learned garbage collection</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Lujing Cen</li>
               <li class="nameList">Ryan Marcus</li>
               <li class="nameList">Hongzi Mao</li>
               <li class="nameList">Justin Gottschlich</li>
               <li class="nameList">Mohammad Alizadeh</li>
               <li class="nameList Last">Tim Kraska</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Several programming languages use garbage collectors (GCs) to automatically manage
                     memory for the programmer. Such collectors must decide when to look for unreachable
                     objects to free, which can have a large performance impact on some applications. In
                     this preliminary work, we propose a design for a learned garbage collector that autonomously
                     learns over time when to perform collections. By using reinforcement learning, our
                     design can incorporate user-defined reward functions, allowing an autonomous garbage
                     collector to learn to optimize the exact metric the user desires (e.g., request latency
                     or queries per second). We conduct an initial experimental study on a prototype, demonstrating
                     that an approach based on tabular Q learning may be promising.
                  </p>
                  	
               </div>
            </div>
            						
            					
         </div>
      </div>
   </body>
</html>